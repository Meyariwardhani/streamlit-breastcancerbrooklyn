# -*- coding: utf-8 -*-
"""Klasifikasi_BreastCancerBrooklyn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14mZi37Lufg64lu79SLF1-YHCvqADeCas

Tentukan Library yang digunakan
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder
from sklearn import svm
from sklearn.metrics import accuracy_score

# Library untuk visualisasi data
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

#for MODEL
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

#for checking testing results
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix

"""Load Dataset"""

data = pd.read_csv('data 1.csv')
data

data.info()

data.head()

data.shape

#Melabeli data yang ada di variabel kategorik menjadi numerik
data[['diagnosis']] = data[['diagnosis']].apply(LabelEncoder().fit_transform)

#view udpated DataFr
data

data['diagnosis'].value_counts()

#Memisahkan data dan label
X = data.drop(columns='diagnosis', axis=1)
Y = data['diagnosis']

print(X)

print(Y)

"""Visualisasi Data"""

data['diagnosis'].unique()

import matplotlib.pyplot as plt
# Menghitung jumlah data untuk setiap kategori pada variabel kategorik
kategori_counts = data['diagnosis'].value_counts()

# Plotting pie chart dengan jumlah data dan persentase
plt.figure(figsize=(8, 8))
plt.pie(kategori_counts, labels=[f'{label} ({count} data, {count / sum(kategori_counts) * 100:.1f}%)' for label, count in zip(kategori_counts.index, kategori_counts)], autopct='', startangle=140)
plt.title('Pie Chart Variabel Diagnosis')
plt.show()

X=data.drop(columns=["diagnosis", "radius_se","texture_se","perimeter_se","area_se","smoothness_se",
                     "compactness_se","concavity_se","concave points_se","symmetry_se","fractal_dimension_se",
                     "radius_worst","texture_worst","perimeter_worst","area_worst","smoothness_worst",
                     "compactness_worst","concavity_worst","concave points_worst","symmetry_worst",
                     "fractal_dimension_worst"])
Y=data["diagnosis"]

X.shape

Y.shape

# initialize figure with 11 subplots in a row
fig, ax = plt.subplots(1, 11, figsize=(50, 35))

# add padding between the subplots
plt.subplots_adjust(wspace=0.5)

# draw boxplot for age in the 1st subplot
sns.boxplot(data=data['radius_mean'], ax=ax[0], color='brown',)
ax[0].set_xlabel('radius_mean')

# draw boxplot for station_distance in the 2nd subplot
sns.boxplot(data=data['texture_mean'], ax=ax[1], color='grey')
ax[1].set_xlabel('texture_mean')

# draw boxplot for stores_count in the 3rd subplot
sns.boxplot(data=data['perimeter_mean'], ax=ax[2], color='yellow')
ax[2].set_xlabel('perimeter_mean')

sns.boxplot(data=data['area_mean'], ax=ax[3], color='pink')
ax[3].set_xlabel('area_mean')

sns.boxplot(data=data['smoothness_mean'], ax=ax[4], color='skyblue')
ax[4].set_xlabel('smoothness_mean')

sns.boxplot(data=data['compactness_mean'], ax=ax[5], color='purple')
ax[5].set_xlabel('compactness_mean')

sns.boxplot(data=data['concavity_mean'], ax=ax[6], color='red')
ax[6].set_xlabel('concavity_mean')

sns.boxplot(data=data['concave points_mean'], ax=ax[7], color='orange')
ax[7].set_xlabel('concave points_mean')

sns.boxplot(data=data['symmetry_mean'], ax=ax[8], color='green')
ax[8].set_xlabel('symmetry_mean')

sns.boxplot(data=data['fractal_dimension_mean'], ax=ax[9], color='blue')
ax[9].set_xlabel('fractal_dimension_mean')

# by default, you'll see x-tick label set to 0 in each subplot
# remove it by setting it to empty list
for subplot in ax:
    subplot.set_xticklabels([])


plt.show()

# Memilih kolom-kolom yang ingin dilihat hubungannya
selected_columns = ['radius_mean','texture_mean','perimeter_mean','area_mean',
                    'smoothness_mean','compactness_mean','concavity_mean','concave points_mean',
                    'symmetry_mean','fractal_dimension_mean']

selected_data = data[selected_columns]

# Membuat pair plot untuk melihat hubungan antar variabel
sns.pairplot(selected_data)
plt.suptitle('Pair Plot: Hubungan Antara Variabel-variabel Numerik')
plt.show()

"""Cek Missing Value"""

#Cek missing value
data.isnull().sum()

"""Transpose data"""

identify = pd.DataFrame({
    'Data Kosong': data.isnull().sum(),
    'Data Duplikat': data.duplicated().sum(),
    'Data NaNN': data.isna().sum(),
    'Type Data': data.dtypes})
identify

data.transpose()

"""One-Hot Encoding"""

#Melabeli data yang ada di variabel kategorik menjadi numerik
data['diagnosis']= data[['diagnosis']].apply(LabelEncoder().fit_transform)

#view udpated DataFr
data

"""Feature Scalling"""

# Import Library
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Inisialisasi MinMaxScaler
scaler = MinMaxScaler()

# Memilih kolom yang ingin di scalling
kolom_scaling = ['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean',
                 'radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se',
                 'radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']

# Melakukan scalling pada kolom yang telah ditentukan
data[kolom_scaling] = scaler.fit_transform(data[kolom_scaling])
data_scal = data
data_scal

"""Data Cleansing"""

#Menghilangkan variabel yang tidak dibutuhkan
data1=data.drop(columns=['id'], inplace=False,axis=1)
data1=data1.drop(columns=['Unnamed: 32'], inplace=False,axis=1)
data1=data1.drop(columns=['radius_se'], inplace=False,axis=1)
data1=data1.drop(columns=['texture_se'], inplace=False,axis=1)
data1=data1.drop(columns=['perimeter_se'], inplace=False,axis=1)
data1=data1.drop(columns=['area_se'], inplace=False,axis=1)
data1=data1.drop(columns=['smoothness_se'], inplace=False,axis=1)
data1=data1.drop(columns=['compactness_se'], inplace=False,axis=1)
data1=data1.drop(columns=['concavity_se'], inplace=False,axis=1)
data1=data1.drop(columns=['concave points_se'], inplace=False,axis=1)
data1=data1.drop(columns=['symmetry_se'], inplace=False,axis=1)
data1=data1.drop(columns=['fractal_dimension_se'], inplace=False,axis=1)
data1=data1.drop(columns=['radius_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['texture_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['perimeter_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['area_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['smoothness_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['compactness_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['concavity_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['concave points_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['symmetry_worst'], inplace=False,axis=1)
data1=data1.drop(columns=['fractal_dimension_worst'], inplace=False,axis=1)
data1

data1.describe()

"""Telaah Data"""

import matplotlib.pyplot as plt

plt.figure(figsize=(22,10))
data1.boxplot()
plt.show()

# Membuat pair plot untuk melihat hubungan antar variabel
sns.scatterplot(data1)
plt.suptitle('Scatter Plot : Apakah ada outlier ?')
plt.show()

identify = pd.DataFrame({
    'Data Kosong': data1.isnull().sum(),
    'Data Duplikat': data1.duplicated().sum(),
    'Data NaNN': data1.isna().sum(),
    'Type Data': data1.dtypes})
identify

X = data1.drop(columns='diagnosis')
y = data1['diagnosis']

columns = ['radius_mean','texture_mean','perimeter_mean','area_mean',
            'smoothness_mean','compactness_mean','concavity_mean','concave points_mean',
            'symmetry_mean','fractal_dimension_mean']

enc = LabelEncoder()
X['radius_mean'] = enc.fit_transform(X['radius_mean'])
X['texture_mean'] = enc.fit_transform(X['texture_mean'])
X['perimeter_mean'] = enc.fit_transform(X['perimeter_mean'])
X['area_mean'] = enc.fit_transform(X['area_mean'])
X['smoothness_mean'] = enc.fit_transform(X['smoothness_mean'])
X['compactness_mean'] = enc.fit_transform(X['compactness_mean'])
X['concavity_mean'] = enc.fit_transform(X['concavity_mean'])
X['concave points_mean'] = enc.fit_transform(X['concave points_mean'])
X['symmetry_mean'] = enc.fit_transform(X['symmetry_mean'])
X['fractal_dimension_mean'] = enc.fit_transform(X['fractal_dimension_mean'])

X

"""Splitting Data"""

#Dilakukan splitting data dengan training 70% dan testing 30%
X = data1.drop(columns='diagnosis')
Y = data1.diagnosis

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
X_train.shape, X_test.shape, Y_train.shape, Y_test.shape

X_train

Y_test

"""Scalling Data"""

columns = ['radius_mean','texture_mean','perimeter_mean','area_mean',
            'smoothness_mean','compactness_mean','concavity_mean','concave points_mean',
            'symmetry_mean','fractal_dimension_mean']

scaler = StandardScaler()
X_train[columns] = scaler.fit_transform(X_train[columns])
X_test[columns] = scaler.transform(X_test[columns])

scaler.fit(X)

standarized_data = scaler.transform(X)

print(standarized_data)

x = standarized_data
Y = data1['diagnosis']

print(X)
print(Y)

import pickle
pickle.dump(scaler, open('scaling_RF.pkl','wb'))

training = pd.DataFrame(X_train)
training

training.to_excel("Data Training 70% Data1.xlsx")

testing = pd.DataFrame(X_test)
testing

testing.to_excel("Data Testing 30% Data1.xlsx")

"""Membuat data latih menggunakan algoritma SVM"""

classifier=svm.SVC(kernel='linear')

classifier.fit(X_train,Y_train)



# Defining parameter range
param_grid = {'C': [0.1, 1, 10, 100],
              'gamma': [1, 0.1, 0.01, 0.001],
              'kernel': ['rbf']}

grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)

# Fitting the model for grid search
grid.fit(X_train, Y_train)

# Print best parameter after tuning
print(grid.best_params_)

# Print how our model looks after hyper-parameter tuning
print(grid.best_estimator_)

"""Membuat model evaluasi untuk mengukur tingkat akurasi"""

X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print('Akurasi data training adalah =', training_data_accuracy)

X_test_prediction = classifier.predict(X_test)
test_data_accuracy =accuracy_score(X_test_prediction, Y_test)

print('Akurasi data testing adalah = ', test_data_accuracy)

grid_predictions = grid.predict(X_test)

# print classification report
print(classification_report(Y_test, grid_predictions))

print ('accuracy_score: ',accuracy_score(Y_test, grid_predictions))

"""Membuat model prediksi"""

input_data =(17.99, 10.38, 122.8, 1001, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419, 0.07871)
input_data_as_numpy_array = np.array(input_data)
input_data_reshape = input_data_as_numpy_array.reshape(1,-1)
std_data = scaler.transform(input_data_reshape)
print(std_data)

prediction = classifier.predict(std_data)
print(prediction)

if(prediction[0] == 0):
  print('Pasien tidak menunjukkan kanker payudara ganas')
else :
  print('Pasien menunjukkan kanker payudara ganas')

hasil_prediksi = pd.DataFrame(grid_predictions)
hasil_prediksi.rename(columns={0:'Prediksi Data1'},inplace=True)
hasil_prediksi.to_excel('Prediksi_Data1.xlsx', index = None)
hasil_prediksi

"""8. Simpan Model"""

import pickle
filename = 'KlasifikasiBreastCancerBrookly_model.sav'
pickle.dump(classifier, open(filename,'wb'))